import { LLMModel } from "@/types/models"

export const llmModels: LLMModel[] = [
  {
    id: "gpt-5-2",
    name: "gpt-5.2",
    displayName: "GPT-5.2",
    provider: "OpenAI",
    category: "llm",
    releaseDate: "2025-12-11",
    contextWindow: 200000,
    maxOutputTokens: 32768,
    inputCost: 20,
    outputCost: 80,
    benchmarks: {
      mmlu: 92.8,
      humanEval: 95.1,
      math: 94.7,
      gsm8k: 98.2,
      gpqa: 67.5,
    },
    capabilities: ["Advanced Reasoning", "Vision", "Code Generation", "Long Context", "Adaptive Thinking"],
    description: "OpenAI's most advanced model with adaptive reasoning and breakthrough performance",
    strengths: ["Top ARC-AGI-2 scores (54.2%)", "Adaptive thinking time", "Excellent at professional tasks", "Strong reasoning"],
    weaknesses: ["Very expensive", "Released in response to competition"],
    useCases: ["Complex reasoning", "Professional tasks", "Advanced coding", "Scientific research"],
    trainingCutoff: "2025-06",
  },
  {
    id: "gemini-3-pro",
    name: "gemini-3-pro",
    displayName: "Gemini 3 Pro",
    provider: "Google",
    category: "llm",
    releaseDate: "2025-11-20",
    contextWindow: 1000000,
    maxOutputTokens: 8192,
    inputCost: 15,
    outputCost: 60,
    benchmarks: {
      mmlu: 91.5,
      humanEval: 93.8,
      math: 93.2,
      gsm8k: 97.9,
      gpqa: 65.8,
    },
    capabilities: ["Deep Think", "Vision", "Audio", "Multimodal", "Long Context"],
    description: "First model to break 1500 LMArena Elo barrier with unprecedented reasoning",
    strengths: ["1501 LMArena Elo", "Deep Think mode", "Multimodal", "1M token context"],
    weaknesses: ["Expensive", "Slower in Deep Think mode"],
    useCases: ["Complex problem solving", "Multimodal analysis", "Research", "Long document processing"],
    trainingCutoff: "2025-08",
  },
  {
    id: "gemini-3-flash",
    name: "gemini-3-flash",
    displayName: "Gemini 3 Flash",
    provider: "Google",
    category: "llm",
    releaseDate: "2025-12-15",
    contextWindow: 1000000,
    maxOutputTokens: 8192,
    inputCost: 0.15,
    outputCost: 0.6,
    benchmarks: {
      mmlu: 85.4,
      humanEval: 87.2,
      math: 84.8,
      gsm8k: 95.3,
    },
    capabilities: ["Ultra Fast", "Long Context", "Multimodal", "Frontier Intelligence"],
    description: "Frontier intelligence built for speed with excellent cost-performance",
    strengths: ["Extremely fast", "Affordable", "1M context", "Strong performance"],
    weaknesses: ["Less capable than Pro version"],
    useCases: ["High-throughput applications", "Real-time processing", "Cost-sensitive deployments"],
    trainingCutoff: "2025-10",
  },
  {
    id: "gpt-5-1",
    name: "gpt-5.1",
    displayName: "GPT-5.1",
    provider: "OpenAI",
    category: "llm",
    releaseDate: "2025-11-18",
    contextWindow: 200000,
    maxOutputTokens: 32768,
    inputCost: 18,
    outputCost: 72,
    benchmarks: {
      mmlu: 91.2,
      humanEval: 94.3,
      math: 93.1,
      gsm8k: 97.8,
      gpqa: 65.2,
    },
    capabilities: ["Adaptive Reasoning", "Vision", "Code Generation", "Long Context"],
    description: "Introduces adaptive reasoning that dynamically adjusts thinking time",
    strengths: ["Adaptive reasoning", "Strong performance", "Dynamic thinking"],
    weaknesses: ["Very expensive", "Released amid intense competition"],
    useCases: ["Complex tasks", "Professional applications", "Research"],
    trainingCutoff: "2025-05",
  },
  {
    id: "gpt-5",
    name: "gpt-5",
    displayName: "GPT-5",
    provider: "OpenAI",
    category: "llm",
    releaseDate: "2025-08-07",
    contextWindow: 200000,
    maxOutputTokens: 32768,
    inputCost: 15,
    outputCost: 60,
    benchmarks: {
      mmlu: 90.4,
      humanEval: 93.5,
      math: 91.8,
      gsm8k: 97.2,
      gpqa: 63.8,
    },
    capabilities: ["Advanced Reasoning", "Vision", "Code Generation", "Long Context"],
    description: "OpenAI's fifth generation flagship model with major improvements",
    strengths: ["Strong reasoning", "Excellent coding", "Multimodal"],
    weaknesses: ["Expensive", "Quickly superseded by 5.1 and 5.2"],
    useCases: ["General purpose", "Professional tasks", "Advanced applications"],
    trainingCutoff: "2025-03",
  },
  {
    id: "claude-opus-4-5",
    name: "claude-opus-4-5",
    displayName: "Claude Opus 4.5",
    provider: "Anthropic",
    category: "llm",
    releaseDate: "2025-11-22",
    contextWindow: 200000,
    maxOutputTokens: 16384,
    inputCost: 15,
    outputCost: 75,
    benchmarks: {
      mmlu: 88.7,
      humanEval: 92.0,
      gpqa: 59.4,
      math: 90.5,
      gsm8k: 96.4,
    },
    capabilities: ["Long Context", "Vision", "Code Generation", "Analysis", "Creative Writing", "Agentic"],
    description: "Anthropic's most intelligent AI model optimized for coding and long-running agents",
    strengths: ["Complex reasoning", "Long-form writing", "Code generation", "Safety", "Agent capabilities"],
    weaknesses: ["Higher cost", "Slower response times", "Lower ARC-AGI-2 score (37.6%)"],
    useCases: ["Research", "Advanced coding", "Content creation", "Data analysis", "AI agents"],
    trainingCutoff: "2025-08",
  },
  {
    id: "claude-sonnet-4-5",
    name: "claude-sonnet-4-5",
    displayName: "Claude Sonnet 4.5",
    provider: "Anthropic",
    category: "llm",
    releaseDate: "2025-11-20",
    contextWindow: 1000000,
    maxOutputTokens: 16384,
    inputCost: 3,
    outputCost: 15,
    benchmarks: {
      mmlu: 88.3,
      humanEval: 93.7,
      gpqa: 59.4,
      math: 90.8,
      gsm8k: 96.4,
    },
    capabilities: ["Long Context", "Vision", "Code Generation", "Fast Responses", "Agentic"],
    description: "Best balance of intelligence, speed, and cost with top SWE-bench performance",
    strengths: ["SWE-bench leader (77.2%)", "Coding excellence", "Fast responses", "Great value", "1M context", "Agent capabilities"],
    weaknesses: ["Slightly less creative than Opus"],
    useCases: ["Software development", "GitHub issue resolution", "Technical writing", "API integration", "Automation", "AI agents"],
    trainingCutoff: "2025-07",
  },
  {
    id: "claude-haiku-4-5",
    name: "claude-haiku-4-5",
    displayName: "Claude 4.5 Haiku",
    provider: "Anthropic",
    category: "llm",
    releaseDate: "2025-11-20",
    contextWindow: 200000,
    maxOutputTokens: 8192,
    inputCost: 0.8,
    outputCost: 4,
    benchmarks: {
      mmlu: 78.5,
      humanEval: 82.3,
      math: 75.8,
      gsm8k: 92.4,
    },
    capabilities: ["Fast", "Long Context", "Vision", "Affordable"],
    description: "Fastest Claude 4.5 model with excellent cost-performance ratio",
    strengths: ["Very fast", "Affordable", "Long context", "Vision", "Good performance"],
    weaknesses: ["Less capable than Sonnet/Opus"],
    useCases: ["High-volume applications", "Real-time chat", "Classification", "Quick tasks"],
    trainingCutoff: "2025-07",
  },
  {
    id: "gemini-2-5-pro",
    name: "gemini-2.5-pro",
    displayName: "Gemini 2.5 Pro",
    provider: "Google",
    category: "llm",
    releaseDate: "2025-03-25",
    contextWindow: 1000000,
    maxOutputTokens: 8192,
    inputCost: 10,
    outputCost: 40,
    benchmarks: {
      mmlu: 89.8,
      humanEval: 91.5,
      math: 89.7,
      gsm8k: 96.8,
      gpqa: 62.4,
    },
    capabilities: ["Deep Think", "Vision", "Audio", "Multimodal", "Long Context"],
    description: "Google's advanced model with Deep Think mode for complex problem solving",
    strengths: ["Deep Think mode", "Step-by-step reasoning", "1M context", "Multimodal"],
    weaknesses: ["Slower in Deep Think mode", "Superseded by Gemini 3"],
    useCases: ["Complex problems", "Research", "Multimodal analysis", "Long documents"],
    trainingCutoff: "2025-01",
  },
  {
    id: "grok-4-1",
    name: "grok-4.1",
    displayName: "Grok 4.1",
    provider: "xAI",
    category: "llm",
    releaseDate: "2025-11-24",
    contextWindow: 131072,
    maxOutputTokens: 8192,
    inputCost: 5,
    outputCost: 15,
    benchmarks: {
      mmlu: 88.9,
      humanEval: 90.7,
      math: 87.3,
      gsm8k: 95.9,
    },
    capabilities: ["Real-time Data", "Vision", "Less Filtered", "X Integration"],
    description: "xAI's latest flagship released amid November 2025 AI model competition",
    strengths: ["Real-time info", "Less censored", "Strong reasoning", "X platform integration"],
    weaknesses: ["Limited availability", "Expensive"],
    useCases: ["Real-time apps", "Less restricted content", "X integration", "Current events"],
    trainingCutoff: "2025-11",
  },
  {
    id: "grok-4-fast",
    name: "grok-4-fast",
    displayName: "Grok 4 Fast",
    provider: "xAI",
    category: "llm",
    releaseDate: "2025-10-15",
    contextWindow: 2000000,
    maxOutputTokens: 8192,
    inputCost: 2,
    outputCost: 8,
    benchmarks: {
      mmlu: 84.2,
      humanEval: 86.4,
      math: 82.1,
      gsm8k: 94.3,
    },
    capabilities: ["Extreme Long Context", "Real-time Data", "Fast", "Vision"],
    description: "World's largest context window at 2M tokens with fast inference",
    strengths: ["2M token context", "Fast", "Real-time info", "Good value"],
    weaknesses: ["Less capable than Grok 4.1"],
    useCases: ["Massive document analysis", "Codebase analysis", "Real-time apps"],
    trainingCutoff: "2025-09",
  },
  {
    id: "deepseek-v3-2",
    name: "deepseek-v3.2",
    displayName: "DeepSeek V3.2",
    provider: "DeepSeek",
    category: "llm",
    releaseDate: "2025-11-10",
    contextWindow: 128000,
    maxOutputTokens: 8192,
    inputCost: 0.6,
    outputCost: 2.4,
    benchmarks: {
      mmlu: 85.7,
      humanEval: 95.8,
      math: 96.2,
      gsm8k: 98.1,
    },
    capabilities: ["Reasoning", "Code", "Math", "Extremely Affordable", "MoE Architecture"],
    description: "Latest iteration with enhanced reasoning and coding at unbeatable price",
    strengths: ["Best-in-class value", "Excellent coding", "Mathematical reasoning", "MoE efficiency"],
    weaknesses: ["Verbose reasoning", "Less creative"],
    useCases: ["Competitive programming", "Math problems", "Budget deployments", "Code generation"],
    trainingCutoff: "2025-08",
  },
  {
    id: "qwen-3",
    name: "qwen-3-72b-instruct",
    displayName: "Qwen 3 72B",
    provider: "Alibaba",
    category: "llm",
    releaseDate: "2025-09-15",
    contextWindow: 131072,
    maxOutputTokens: 8192,
    inputCost: 0.9,
    outputCost: 0.9,
    benchmarks: {
      mmlu: 87.8,
      humanEval: 89.2,
      math: 84.5,
      gsm8k: 96.7,
    },
    capabilities: ["Open Source", "Multilingual", "Code", "Math", "Long Context"],
    description: "Third generation Qwen with improved multilingual and reasoning capabilities",
    strengths: ["Open source", "Excellent Chinese", "Strong code", "Math", "Great value"],
    weaknesses: ["Less known in West"],
    useCases: ["Chinese language", "Open deployments", "Multilingual", "Self-hosting"],
    trainingCutoff: "2025-07",
  },
  {
    id: "gpt-4-turbo",
    name: "gpt-4-turbo-2024-04-09",
    displayName: "GPT-4 Turbo",
    provider: "OpenAI",
    category: "llm",
    releaseDate: "2024-04-09",
    contextWindow: 128000,
    maxOutputTokens: 4096,
    inputCost: 10,
    outputCost: 30,
    benchmarks: {
      mmlu: 86.4,
      humanEval: 87.2,
      math: 72.3,
      gsm8k: 94.2,
    },
    capabilities: ["Vision", "JSON Mode", "Function Calling", "Long Context"],
    description: "OpenAI's most capable GPT-4 variant with vision and extended context",
    strengths: ["Vision capabilities", "JSON mode", "Tool use", "Well-documented"],
    weaknesses: ["Moderate cost", "Not the fastest"],
    useCases: ["Multimodal applications", "Structured output", "General purpose"],
    trainingCutoff: "2023-12",
  },
  {
    id: "gpt-4o",
    name: "gpt-4o-2024-11-20",
    displayName: "GPT-4o",
    provider: "OpenAI",
    category: "llm",
    releaseDate: "2024-11-20",
    contextWindow: 128000,
    maxOutputTokens: 16384,
    inputCost: 2.5,
    outputCost: 10,
    benchmarks: {
      mmlu: 87.2,
      humanEval: 90.2,
      math: 76.6,
      gsm8k: 95.8,
    },
    capabilities: ["Vision", "Audio", "Fast", "Function Calling"],
    description: "Omni-modal model with native audio, vision, and text capabilities",
    strengths: ["Multimodal", "Fast", "Affordable", "High output limit"],
    weaknesses: ["Slightly less reasoning than GPT-4 Turbo"],
    useCases: ["Real-time apps", "Multimodal processing", "Cost-sensitive deployments"],
    trainingCutoff: "2023-10",
  },
  {
    id: "gemini-1-5-pro",
    name: "gemini-1.5-pro",
    displayName: "Gemini 1.5 Pro",
    provider: "Google",
    category: "llm",
    releaseDate: "2024-05-14",
    contextWindow: 2000000,
    maxOutputTokens: 8192,
    inputCost: 1.25,
    outputCost: 5,
    benchmarks: {
      mmlu: 85.9,
      humanEval: 84.1,
      math: 67.7,
      gsm8k: 91.7,
    },
    capabilities: ["Extreme Long Context", "Vision", "Audio", "Video Understanding"],
    description: "Google's flagship model with unprecedented 2M token context window",
    strengths: ["Massive context", "Multimodal", "Affordable", "Video understanding"],
    weaknesses: ["Rate limits", "Occasional inconsistency"],
    useCases: ["Document analysis", "Video processing", "Large codebase analysis"],
    trainingCutoff: "2024-01",
  },
  {
    id: "deepseek-r1",
    name: "deepseek-r1",
    displayName: "DeepSeek R1",
    provider: "DeepSeek",
    category: "llm",
    releaseDate: "2025-01-20",
    contextWindow: 64000,
    maxOutputTokens: 8192,
    inputCost: 0.55,
    outputCost: 2.19,
    benchmarks: {
      mmlu: 79.8,
      humanEval: 96.3,
      math: 97.3,
      gsm8k: 98.5,
    },
    capabilities: ["Reasoning", "Code", "Math", "Extremely Affordable"],
    description: "Reasoning-focused model with exceptional math and coding performance",
    strengths: ["Best-in-class coding", "Mathematical reasoning", "Incredible value"],
    weaknesses: ["Verbose reasoning traces", "Less creative"],
    useCases: ["Competitive programming", "Math problems", "Budget deployments"],
    trainingCutoff: "2024-06",
  },
  {
    id: "o1-preview",
    name: "o1-preview",
    displayName: "OpenAI o1-preview",
    provider: "OpenAI",
    category: "llm",
    releaseDate: "2024-09-12",
    contextWindow: 128000,
    maxOutputTokens: 32768,
    inputCost: 15,
    outputCost: 60,
    benchmarks: {
      mmlu: 92.3,
      math: 96.4,
      gpqa: 78.3,
    },
    capabilities: ["Advanced Reasoning", "Chain of Thought", "Science", "Math"],
    description: "Reasoning model with extended thinking capabilities for complex problems",
    strengths: ["Complex reasoning", "Scientific tasks", "Math proofs", "Code debugging"],
    weaknesses: ["Very expensive", "Slow", "No streaming", "No system messages"],
    useCases: ["Research problems", "Algorithm design", "Scientific computing"],
    trainingCutoff: "2023-10",
  },
  {
    id: "o1-mini",
    name: "o1-mini",
    displayName: "OpenAI o1-mini",
    provider: "OpenAI",
    category: "llm",
    releaseDate: "2024-09-12",
    contextWindow: 128000,
    maxOutputTokens: 65536,
    inputCost: 3,
    outputCost: 12,
    benchmarks: {
      mmlu: 85.2,
      humanEval: 94.6,
      math: 90.0,
    },
    capabilities: ["Reasoning", "Code", "Math", "Science"],
    description: "Faster, more affordable reasoning model focused on STEM",
    strengths: ["Strong coding", "Good math", "Better value than o1", "Faster"],
    weaknesses: ["Less capable than o1-preview", "No streaming"],
    useCases: ["Code debugging", "Technical problems", "STEM tutoring"],
    trainingCutoff: "2023-10",
  },
  {
    id: "llama-3-1-405b",
    name: "llama-3.1-405b-instruct",
    displayName: "Llama 3.1 405B",
    provider: "Meta",
    category: "llm",
    releaseDate: "2024-07-23",
    contextWindow: 128000,
    maxOutputTokens: 4096,
    inputCost: 2.7,
    outputCost: 2.7,
    benchmarks: {
      mmlu: 88.6,
      humanEval: 89.0,
      math: 73.8,
      gsm8k: 96.8,
    },
    capabilities: ["Open Source", "Long Context", "Multilingual", "Function Calling"],
    description: "Meta's largest open-source model rivaling GPT-4",
    strengths: ["Open source", "Strong performance", "Multilingual", "No vendor lock-in"],
    weaknesses: ["Requires hosting", "Large model size"],
    useCases: ["Self-hosting", "Custom deployments", "Research"],
    trainingCutoff: "2023-12",
  },
  {
    id: "llama-3-1-70b",
    name: "llama-3.1-70b-instruct",
    displayName: "Llama 3.1 70B",
    provider: "Meta",
    category: "llm",
    releaseDate: "2024-07-23",
    contextWindow: 128000,
    maxOutputTokens: 4096,
    inputCost: 0.88,
    outputCost: 0.88,
    benchmarks: {
      mmlu: 86.0,
      humanEval: 80.5,
      math: 68.0,
      gsm8k: 95.1,
    },
    capabilities: ["Open Source", "Long Context", "Efficient", "Multilingual"],
    description: "Efficient open-source model with strong general capabilities",
    strengths: ["Great value", "Open source", "Efficient", "Good performance"],
    weaknesses: ["Not as capable as 405B variant"],
    useCases: ["Cost-effective deployments", "General purpose", "Self-hosting"],
    trainingCutoff: "2023-12",
  },
  {
    id: "mistral-large-2",
    name: "mistral-large-2407",
    displayName: "Mistral Large 2",
    provider: "Mistral",
    category: "llm",
    releaseDate: "2024-07-24",
    contextWindow: 128000,
    maxOutputTokens: 4096,
    inputCost: 3,
    outputCost: 9,
    benchmarks: {
      mmlu: 84.0,
      humanEval: 92.0,
      math: 73.0,
      gsm8k: 93.0,
    },
    capabilities: ["Function Calling", "JSON Mode", "Multilingual", "Code"],
    description: "Mistral's flagship model with strong coding and multilingual abilities",
    strengths: ["Excellent coding", "Multilingual", "European provider", "Function calling"],
    weaknesses: ["Smaller ecosystem", "Limited availability"],
    useCases: ["European deployments", "Multilingual apps", "Code generation"],
    trainingCutoff: "2024-04",
  },
  {
    id: "mistral-medium",
    name: "mistral-medium-2312",
    displayName: "Mistral Medium",
    provider: "Mistral",
    category: "llm",
    releaseDate: "2023-12-11",
    contextWindow: 32000,
    maxOutputTokens: 4096,
    inputCost: 2.7,
    outputCost: 8.1,
    benchmarks: {
      mmlu: 75.3,
      humanEval: 76.0,
    },
    capabilities: ["Function Calling", "JSON Mode", "Multilingual"],
    description: "Balanced model for general-purpose tasks",
    strengths: ["Good balance", "Reasonable cost", "Multilingual"],
    weaknesses: ["Outclassed by newer models"],
    useCases: ["General purpose", "Legacy deployments"],
    trainingCutoff: "2023-09",
  },
  {
    id: "grok-2",
    name: "grok-2-1212",
    displayName: "Grok 2",
    provider: "xAI",
    category: "llm",
    releaseDate: "2024-12-12",
    contextWindow: 131072,
    maxOutputTokens: 4096,
    inputCost: 2,
    outputCost: 10,
    benchmarks: {
      mmlu: 87.5,
      humanEval: 88.4,
      math: 76.1,
    },
    capabilities: ["Real-time Data", "Vision", "Less Filtered"],
    description: "xAI's flagship model with real-time search integration",
    strengths: ["Real-time info", "Less censored", "Strong reasoning"],
    weaknesses: ["Limited availability", "Newer ecosystem"],
    useCases: ["Real-time apps", "Less restricted content", "X integration"],
    trainingCutoff: "2024-11",
  },
  {
    id: "command-r-plus",
    name: "command-r-plus",
    displayName: "Command R+",
    provider: "Cohere",
    category: "llm",
    releaseDate: "2024-04-04",
    contextWindow: 128000,
    maxOutputTokens: 4096,
    inputCost: 3,
    outputCost: 15,
    benchmarks: {
      mmlu: 75.0,
      humanEval: 70.0,
    },
    capabilities: ["RAG Optimized", "Tool Use", "Multilingual", "Enterprise"],
    description: "Enterprise-focused model optimized for retrieval-augmented generation",
    strengths: ["RAG optimization", "Tool use", "Enterprise features", "Citations"],
    weaknesses: ["Lower benchmark scores"],
    useCases: ["RAG applications", "Enterprise search", "Document QA"],
    trainingCutoff: "2024-03",
  },
  {
    id: "claude-haiku-4",
    name: "claude-haiku-4-20250514",
    displayName: "Claude 4 Haiku",
    provider: "Anthropic",
    category: "llm",
    releaseDate: "2024-05-14",
    contextWindow: 200000,
    maxOutputTokens: 8192,
    inputCost: 0.8,
    outputCost: 4,
    benchmarks: {
      mmlu: 75.2,
      humanEval: 75.9,
    },
    capabilities: ["Fast", "Long Context", "Vision", "Affordable"],
    description: "Fastest Claude model with excellent cost-performance ratio",
    strengths: ["Very fast", "Affordable", "Long context", "Vision"],
    weaknesses: ["Less capable than Sonnet/Opus"],
    useCases: ["High-volume applications", "Real-time chat", "Classification"],
    trainingCutoff: "2024-03",
  },
  {
    id: "gpt-3-5-turbo",
    name: "gpt-3.5-turbo-0125",
    displayName: "GPT-3.5 Turbo",
    provider: "OpenAI",
    category: "llm",
    releaseDate: "2024-01-25",
    contextWindow: 16385,
    maxOutputTokens: 4096,
    inputCost: 0.5,
    outputCost: 1.5,
    benchmarks: {
      mmlu: 70.0,
      humanEval: 76.8,
    },
    capabilities: ["Fast", "Affordable", "Function Calling"],
    description: "Classic affordable model for simple tasks",
    strengths: ["Very affordable", "Fast", "Proven track record"],
    weaknesses: ["Significantly less capable than GPT-4"],
    useCases: ["Simple tasks", "High-volume low-complexity", "Testing"],
    trainingCutoff: "2021-09",
  },
  {
    id: "gemini-flash-2",
    name: "gemini-flash-2.0",
    displayName: "Gemini 2.0 Flash",
    provider: "Google",
    category: "llm",
    releaseDate: "2024-12-11",
    contextWindow: 1048576,
    maxOutputTokens: 8192,
    inputCost: 0.1,
    outputCost: 0.4,
    benchmarks: {
      mmlu: 71.9,
      humanEval: 74.4,
    },
    capabilities: ["Ultra Fast", "Long Context", "Multimodal", "Extremely Affordable"],
    description: "Google's fastest model with million+ token context",
    strengths: ["Incredibly fast", "Cheap", "1M+ context", "Multimodal"],
    weaknesses: ["Lower capability than Pro models"],
    useCases: ["High throughput", "Large documents", "Real-time apps"],
    trainingCutoff: "2024-08",
  },
  {
    id: "amazon-nova-pro",
    name: "amazon-nova-pro-v1",
    displayName: "Amazon Nova Pro",
    provider: "Amazon",
    category: "llm",
    releaseDate: "2024-12-03",
    contextWindow: 300000,
    maxOutputTokens: 5000,
    inputCost: 0.8,
    outputCost: 3.2,
    benchmarks: {
      mmlu: 78.7,
      humanEval: 84.0,
    },
    capabilities: ["Long Context", "Vision", "AWS Native", "RAG"],
    description: "AWS native model optimized for Bedrock integration",
    strengths: ["AWS integration", "Long context", "Good value", "Enterprise support"],
    weaknesses: ["AWS only", "Newer model"],
    useCases: ["AWS deployments", "Enterprise applications"],
    trainingCutoff: "2024-08",
  },
  {
    id: "phi-4",
    name: "phi-4",
    displayName: "Phi-4",
    provider: "Microsoft",
    category: "llm",
    releaseDate: "2024-12-12",
    contextWindow: 16384,
    maxOutputTokens: 4096,
    inputCost: 0.1,
    outputCost: 0.1,
    benchmarks: {
      mmlu: 84.8,
      humanEval: 82.6,
      math: 80.4,
    },
    capabilities: ["Small Model", "Math", "Reasoning", "Efficient"],
    description: "Small language model with impressive reasoning for its size",
    strengths: ["Efficient", "Strong math", "Small footprint", "Open source"],
    weaknesses: ["Limited context", "Smaller knowledge base"],
    useCases: ["Edge deployment", "Resource-constrained", "Local inference"],
    trainingCutoff: "2024-06",
  },
  {
    id: "qwen-2-5-72b",
    name: "qwen-2.5-72b-instruct",
    displayName: "Qwen 2.5 72B",
    provider: "Alibaba",
    category: "llm",
    releaseDate: "2024-09-19",
    contextWindow: 131072,
    maxOutputTokens: 8192,
    inputCost: 0.9,
    outputCost: 0.9,
    benchmarks: {
      mmlu: 85.3,
      humanEval: 86.0,
      math: 80.0,
    },
    capabilities: ["Open Source", "Multilingual", "Code", "Math"],
    description: "Chinese open-source model with strong multilingual capabilities",
    strengths: ["Open source", "Excellent Chinese", "Strong code", "Math"],
    weaknesses: ["Less known in West"],
    useCases: ["Chinese language", "Open deployments", "Multilingual"],
    trainingCutoff: "2024-06",
  },
  {
    id: "claude-3-opus",
    name: "claude-3-opus-20240229",
    displayName: "Claude 3 Opus",
    provider: "Anthropic",
    category: "llm",
    releaseDate: "2024-02-29",
    contextWindow: 200000,
    maxOutputTokens: 4096,
    inputCost: 15,
    outputCost: 75,
    benchmarks: {
      mmlu: 86.8,
      humanEval: 84.9,
      gpqa: 50.4,
    },
    capabilities: ["Long Context", "Vision", "Analysis", "Creative"],
    description: "Previous generation flagship from Anthropic",
    strengths: ["Strong reasoning", "Long context", "Vision", "Safety"],
    weaknesses: ["Superseded by 4.5 series"],
    useCases: ["Legacy applications"],
    trainingCutoff: "2023-08",
  },
  {
    id: "yi-large",
    name: "yi-large",
    displayName: "Yi Large",
    provider: "01.AI",
    category: "llm",
    releaseDate: "2024-05-13",
    contextWindow: 32768,
    maxOutputTokens: 4096,
    inputCost: 3,
    outputCost: 3,
    benchmarks: {
      mmlu: 76.3,
      humanEval: 77.9,
    },
    capabilities: ["Bilingual", "Code", "Long Context"],
    description: "Bilingual model from 01.AI with strong Chinese performance",
    strengths: ["Chinese language", "Good value", "Code generation"],
    weaknesses: ["Smaller model ecosystem"],
    useCases: ["Chinese applications", "Bilingual content"],
    trainingCutoff: "2024-02",
  },
  {
    id: "perplexity-sonar-large",
    name: "sonar-large-32k-online",
    displayName: "Sonar Large Online",
    provider: "Perplexity",
    category: "llm",
    releaseDate: "2024-01-31",
    contextWindow: 32768,
    maxOutputTokens: 4096,
    inputCost: 1,
    outputCost: 1,
    benchmarks: {
      mmlu: 72.0,
    },
    capabilities: ["Real-time Search", "Citations", "Web Access"],
    description: "Search-augmented model with real-time web access",
    strengths: ["Real-time info", "Citations", "Search integration"],
    weaknesses: ["Dependent on search quality"],
    useCases: ["Current events", "Research", "Fact-checking"],
    trainingCutoff: "Live",
  },
  {
    id: "databricks-dbrx",
    name: "dbrx-instruct",
    displayName: "DBRX Instruct",
    provider: "Databricks",
    category: "llm",
    releaseDate: "2024-03-27",
    contextWindow: 32768,
    maxOutputTokens: 4096,
    inputCost: 0.75,
    outputCost: 2.25,
    benchmarks: {
      mmlu: 73.7,
      humanEval: 70.8,
    },
    capabilities: ["Open Source", "MoE Architecture", "Enterprise"],
    description: "Mixture-of-experts model optimized for enterprise",
    strengths: ["Open source", "Efficient MoE", "Enterprise focus"],
    weaknesses: ["Moderate performance"],
    useCases: ["Enterprise deployments", "Data workloads"],
    trainingCutoff: "2024-01",
  },
  {
    id: "ai21-jamba",
    name: "jamba-1.5-large",
    displayName: "Jamba 1.5 Large",
    provider: "AI21 Labs",
    category: "llm",
    releaseDate: "2024-08-08",
    contextWindow: 256000,
    maxOutputTokens: 4096,
    inputCost: 2,
    outputCost: 8,
    benchmarks: {
      mmlu: 80.3,
      humanEval: 68.2,
    },
    capabilities: ["Extremely Long Context", "Hybrid Architecture", "Multilingual"],
    description: "Hybrid SSM-Transformer with 256K context window",
    strengths: ["256K context", "Unique architecture", "Multilingual"],
    weaknesses: ["Lower coding performance"],
    useCases: ["Long document analysis", "Research"],
    trainingCutoff: "2024-03",
  },
  {
    id: "inflection-pi",
    name: "inflection-2.5",
    displayName: "Inflection 2.5 (Pi)",
    provider: "Inflection",
    category: "llm",
    releaseDate: "2024-03-07",
    contextWindow: 32768,
    maxOutputTokens: 4096,
    inputCost: 0,
    outputCost: 0,
    benchmarks: {
      mmlu: 78.0,
    },
    capabilities: ["Conversational", "Empathetic", "Free"],
    description: "Personal intelligence model optimized for conversation",
    strengths: ["Empathetic", "Conversational", "Free to use"],
    weaknesses: ["Not optimized for tasks", "Limited availability"],
    useCases: ["Chat applications", "Personal assistant"],
    trainingCutoff: "2023-11",
  },
  {
    id: "reka-core",
    name: "reka-core-20240501",
    displayName: "Reka Core",
    provider: "Reka AI",
    category: "llm",
    releaseDate: "2024-05-01",
    contextWindow: 128000,
    maxOutputTokens: 4096,
    inputCost: 3,
    outputCost: 15,
    benchmarks: {
      mmlu: 78.8,
      humanEval: 74.8,
    },
    capabilities: ["Multimodal", "Vision", "Audio", "Video"],
    description: "Truly multimodal model with native vision, audio, and video",
    strengths: ["Native multimodal", "Video understanding"],
    weaknesses: ["Smaller ecosystem", "Limited availability"],
    useCases: ["Multimodal applications", "Video analysis"],
    trainingCutoff: "2024-02",
  },
  {
    id: "nvidia-nemotron",
    name: "nemotron-4-340b-instruct",
    displayName: "Nemotron 4 340B",
    provider: "NVIDIA",
    category: "llm",
    releaseDate: "2024-06-14",
    contextWindow: 4096,
    maxOutputTokens: 4096,
    inputCost: 0,
    outputCost: 0,
    benchmarks: {
      mmlu: 81.0,
      humanEval: 73.0,
    },
    capabilities: ["Open Source", "RLHF Optimized", "Free"],
    description: "NVIDIA's open model optimized for helpfulness",
    strengths: ["Open source", "Free", "RLHF tuned", "Helpful"],
    weaknesses: ["Smaller context", "Requires GPU"],
    useCases: ["Self-hosting", "NVIDIA hardware", "Research"],
    trainingCutoff: "2024-01",
  },
  {
    id: "writer-palmyra-x-004",
    name: "palmyra-x-004",
    displayName: "Palmyra X 004",
    provider: "Writer",
    category: "llm",
    releaseDate: "2024-11-12",
    contextWindow: 128000,
    maxOutputTokens: 8192,
    inputCost: 2.5,
    outputCost: 10,
    benchmarks: {
      mmlu: 75.0,
    },
    capabilities: ["Enterprise", "Graph RAG", "Knowledge Graphs"],
    description: "Enterprise model with knowledge graph integration",
    strengths: ["Enterprise features", "Knowledge graphs", "Graph RAG"],
    weaknesses: ["Niche use case"],
    useCases: ["Enterprise knowledge management", "Graph-based RAG"],
    trainingCutoff: "2024-06",
  },
]
